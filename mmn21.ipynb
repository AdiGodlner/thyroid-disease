{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4359455b",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5cf6e8a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9172"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "continuous = \"continuous\"\n",
    "# read data \n",
    "binary_values = [\"f\",\"t\"]\n",
    "col_info={\"age\": continuous,\n",
    "          \"sex\":[\"M\", \"F\"],\n",
    "          \"on thyroxine\":binary_values,\n",
    "          \"query on thyroxine\":binary_values,\n",
    "          \"on antithyroid medication\":binary_values,\n",
    "          \"sick\":binary_values,\n",
    "          \"pregnant\":binary_values,\n",
    "          \"thyroid surgery\":binary_values,\n",
    "          \"I131 treatment\":binary_values,\n",
    "          \"query hypothyroid\":binary_values,\n",
    "          \"query hyperthyroid\":binary_values,\n",
    "          \"lithium\":binary_values,\n",
    "          \"goitre\":binary_values,\n",
    "          \"tumor\":binary_values,\n",
    "          \"hypopituitary\":binary_values,\n",
    "          \"psych\":binary_values,\n",
    "          \"TSH measured\":binary_values,\n",
    "          \"TSH\":continuous,\n",
    "          \"T3 measured\":binary_values,\n",
    "          \"T3\":continuous,\n",
    "          \"TT4 measured\":binary_values,\n",
    "          \"TT4\":continuous,\n",
    "          \"T4U measured\":binary_values,\n",
    "          \"T4U\":continuous,\n",
    "          \"FTI measured\":binary_values,\n",
    "          \"FTI\":continuous,\n",
    "          \"TBG measured\":binary_values,\n",
    "          \"TBG\":continuous,\n",
    "          \"referral source\": [\"WEST\", \"STMW\", \"SVHC\", \"SVI\", \"SVHD\", \"other\"],\n",
    "          \"record identification\":continuous\n",
    "          } \n",
    "\n",
    "data_url = \"./thyroid+disease/thyroid0387.data\"\n",
    "# data_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/thyroid-disease/thyroid0387.data\"\n",
    "df = pd.read_csv(data_url, names=col_info.keys(), header=None, index_col=False)\n",
    "df.shape[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83c853a",
   "metadata": {},
   "source": [
    "# Data cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eed0d6ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toatl number of rows : 9172 \n",
      "=====================\n",
      "sex column has 307 NA values\n",
      "TSH column has 842 NA values\n",
      "T3 column has 2604 NA values\n",
      "TT4 column has 442 NA values\n",
      "T4U column has 809 NA values\n",
      "FTI column has 802 NA values\n",
      "TBG column has 8823 NA values\n",
      "=====================\n",
      "TSH :\n",
      "Rows with measurement = 8330\n",
      "Valid measurement count = 8330\n",
      "Invalid measurement count = 0\n",
      "Measurement taken without request count = 0\n",
      "=======================\n",
      "\n",
      "T3 :\n",
      "Rows with measurement = 6568\n",
      "Valid measurement count = 6568\n",
      "Invalid measurement count = 0\n",
      "Measurement taken without request count = 0\n",
      "=======================\n",
      "\n",
      "TT4 :\n",
      "Rows with measurement = 8730\n",
      "Valid measurement count = 8730\n",
      "Invalid measurement count = 0\n",
      "Measurement taken without request count = 0\n",
      "=======================\n",
      "\n",
      "T4U :\n",
      "Rows with measurement = 8363\n",
      "Valid measurement count = 8363\n",
      "Invalid measurement count = 0\n",
      "Measurement taken without request count = 0\n",
      "=======================\n",
      "\n",
      "FTI :\n",
      "Rows with measurement = 8370\n",
      "Valid measurement count = 8370\n",
      "Invalid measurement count = 0\n",
      "Measurement taken without request count = 0\n",
      "=======================\n",
      "\n",
      "TBG :\n",
      "Rows with measurement = 349\n",
      "Valid measurement count = 349\n",
      "Invalid measurement count = 0\n",
      "Measurement taken without request count = 0\n",
      "=======================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check for NA values in data \n",
    "\n",
    "df.replace(\"?\", pd.NA, inplace=True)\n",
    "\n",
    "incompelete_columns = []\n",
    "\n",
    "# check which columns have a large amount of missing data\n",
    "print(f\"toatl number of rows : {df.shape[0]} \")\n",
    "print(\"=====================\")\n",
    "for name in col_info.keys():\n",
    "    na_count = df[name].isna().sum()\n",
    "    if na_count != 0:\n",
    "        incompelete_columns.append(name)\n",
    "        print(f\"{name} column has {na_count} NA values\")\n",
    "   \n",
    "\n",
    "print(\"=====================\")\n",
    "\n",
    "# to see if there are missing values for tests that where conducted \n",
    "# Get columns related to measurements\n",
    "measurement_related_cols = [key for key in col_info.keys() if \"measured\" in key]\n",
    "\n",
    "for measurement_col in measurement_related_cols:    \n",
    "    # Select rows where measurement was conducted\n",
    "    rows_with_measurement = df[df[measurement_col] == \"t\"]\n",
    "    rows_without_measurement = df[df[measurement_col] == \"f\"]\n",
    "    \n",
    "    measurement_name = measurement_col.split()[0]\n",
    "    # Count the number of valid measurements\n",
    "    valid_measurement_count = rows_with_measurement[measurement_name].notna().sum()\n",
    "    # Count the number of invalid measurements\n",
    "    invalid_measurement_count = rows_with_measurement[measurement_name].isna().sum()\n",
    "    # Count the number of measurements taken without being requested\n",
    "    measurement_without_request_count = rows_without_measurement[measurement_name].notna().sum()\n",
    "    \n",
    "    # Print the results\n",
    "    print(f\"{measurement_name} :\\n\"\n",
    "          f\"Rows with measurement = {rows_with_measurement.shape[0]}\\n\"\n",
    "          f\"Valid measurement count = {valid_measurement_count}\\n\"\n",
    "          f\"Invalid measurement count = {invalid_measurement_count}\\n\"\n",
    "          f\"Measurement taken without request count = {measurement_without_request_count}\\n\"\n",
    "          \"=======================\\n\"\n",
    "         )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99bafed",
   "metadata": {},
   "source": [
    "as we can see above we have found some columns with missing data and need to see what we do about it \n",
    "we also found that no missing data exists for mesurments that where taken for </br>\n",
    "\n",
    "TSH  \n",
    "T3  \n",
    "TT4  \n",
    "T4U  \n",
    "FTI  \n",
    "TBG\n",
    "\n",
    "there for all missing values for those columns are for tests that were not conducted and so \n",
    "should remain NA TODO reward the entire thing later \n",
    "\n",
    "we can also see that everywhere we have a value for a column named messurment it was preformed there for we can drop the messurment columns as they are suporflous data \n",
    "additionaly this saves us the trouble of checking if the model that we train on the data \n",
    "we should note that some of the missing data is for test that might not have been taken and so there shoulddnt be any values \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f5938e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'sex', 'on thyroxine', 'query on thyroxine', 'on antithyroid medication', 'sick', 'pregnant', 'thyroid surgery', 'I131 treatment', 'query hypothyroid', 'query hyperthyroid', 'lithium', 'goitre', 'tumor', 'hypopituitary', 'psych', 'TSH', 'T3', 'TT4', 'T4U', 'FTI', 'TBG', 'referral source', 'record identification']\n"
     ]
    }
   ],
   "source": [
    "# droping messured columns as described earlyier \n",
    "df.drop(columns=measurement_related_cols, inplace=True)\n",
    "# remove from col_info for later preprocessing \n",
    "for col in measurement_related_cols:\n",
    "    col_info.pop(col ,None)\n",
    "\n",
    "column_names = df.columns.tolist()\n",
    "\n",
    "# Print the column names\n",
    "print(column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "41f2d067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex_counts before : sex\n",
      "F    6073\n",
      "M    2792\n",
      "Name: count, dtype: int64\n",
      "sex_counts after pregnenet : sex\n",
      "F    6077\n",
      "M    2792\n",
      "Name: count, dtype: int64\n",
      "sex_counts after : sex\n",
      "F    6278\n",
      "M    2894\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# fill in missing sex col values \n",
    "import numpy as np\n",
    "sex_counts = df[\"sex\"].value_counts()\n",
    "print(f\"sex_counts before : {sex_counts}\")\n",
    "\n",
    "# if sex is NA and pregenent is True then we set sex to female\n",
    "df.loc[(df[\"sex\"].isna()) & (df[\"pregnant\"] == \"t\"), \"sex\"] = \"F\"\n",
    "# Count the occurrences of each sex\n",
    "sex_counts = df[\"sex\"].value_counts()\n",
    "print(f\"sex_counts after pregnenet : {sex_counts}\")\n",
    "# fill in missing sex col values with the same distribution of the sex that appear in the df \n",
    "# Calculate the proportion of each sex\n",
    "total_count = sex_counts.sum()\n",
    "male_proportion = sex_counts.get('M', 0) / total_count\n",
    "female_proportion = sex_counts.get('F', 0) / total_count\n",
    "\n",
    "# Fill missing values randomly based on the distribution\n",
    "missing_indices = df[df['sex'].isna()].index\n",
    "missing_count = len(missing_indices)\n",
    "fill_values = np.random.choice(['M', 'F'], size=missing_count,\n",
    "                               p=[male_proportion, female_proportion])\n",
    "df.loc[missing_indices, 'sex'] = fill_values\n",
    "sex_counts = df['sex'].value_counts()\n",
    "print(f\"sex_counts after : {sex_counts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff7503bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>on thyroxine</th>\n",
       "      <th>query on thyroxine</th>\n",
       "      <th>on antithyroid medication</th>\n",
       "      <th>sick</th>\n",
       "      <th>pregnant</th>\n",
       "      <th>thyroid surgery</th>\n",
       "      <th>I131 treatment</th>\n",
       "      <th>query hypothyroid</th>\n",
       "      <th>...</th>\n",
       "      <th>psych</th>\n",
       "      <th>TSH</th>\n",
       "      <th>T3</th>\n",
       "      <th>TT4</th>\n",
       "      <th>T4U</th>\n",
       "      <th>FTI</th>\n",
       "      <th>TBG</th>\n",
       "      <th>referral source</th>\n",
       "      <th>record identification</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29</td>\n",
       "      <td>F</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>...</td>\n",
       "      <td>f</td>\n",
       "      <td>0.3</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>other</td>\n",
       "      <td>-[840801013]</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29</td>\n",
       "      <td>F</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>...</td>\n",
       "      <td>f</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>128</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>other</td>\n",
       "      <td>-[840801014]</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>F</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>...</td>\n",
       "      <td>f</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>11</td>\n",
       "      <td>other</td>\n",
       "      <td>-[840801042]</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36</td>\n",
       "      <td>F</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>...</td>\n",
       "      <td>f</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>26</td>\n",
       "      <td>other</td>\n",
       "      <td>-[840803046]</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>F</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>...</td>\n",
       "      <td>f</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>36</td>\n",
       "      <td>other</td>\n",
       "      <td>S[840803047]</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age sex on thyroxine query on thyroxine on antithyroid medication sick  \\\n",
       "0   29   F            f                  f                         f    f   \n",
       "1   29   F            f                  f                         f    f   \n",
       "2   41   F            f                  f                         f    f   \n",
       "3   36   F            f                  f                         f    f   \n",
       "4   32   F            f                  f                         f    f   \n",
       "\n",
       "  pregnant thyroid surgery I131 treatment query hypothyroid  ... psych   TSH  \\\n",
       "0        f               f              f                 t  ...     f   0.3   \n",
       "1        f               f              f                 f  ...     f   1.6   \n",
       "2        f               f              f                 f  ...     f  <NA>   \n",
       "3        f               f              f                 f  ...     f  <NA>   \n",
       "4        f               f              f                 f  ...     f  <NA>   \n",
       "\n",
       "     T3   TT4   T4U   FTI   TBG referral source record identification  \\\n",
       "0  <NA>  <NA>  <NA>  <NA>  <NA>           other          -[840801013]   \n",
       "1   1.9   128  <NA>  <NA>  <NA>           other          -[840801014]   \n",
       "2  <NA>  <NA>  <NA>  <NA>    11           other          -[840801042]   \n",
       "3  <NA>  <NA>  <NA>  <NA>    26           other          -[840803046]   \n",
       "4  <NA>  <NA>  <NA>  <NA>    36           other          S[840803047]   \n",
       "\n",
       "  diagnosis  \n",
       "0         -  \n",
       "1         -  \n",
       "2         -  \n",
       "3         -  \n",
       "4         S  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the diagnosis from the last column and put it in a new column \n",
    "diagnosis_pattern = r\"(.*)(?=\\[\\d*\\])\" \n",
    "df[\"diagnosis\"] = df[\"record identification\"].str.extract(diagnosis_pattern)\n",
    "\n",
    "# extract the number from the 'record_identification' column\n",
    "# df[\"record identification\"] = df[\"record identification\"].str.extract(r\"\\[(\\d+)\\]\")\n",
    "# Print column names\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bdeafd67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete dulpicate rows : 0\n",
      "rows with duplicated record identification 0\n"
     ]
    }
   ],
   "source": [
    "# check for duplicate rows\n",
    "duplicate_rows = df.duplicated()\n",
    "duplicated_df = df[duplicate_rows]\n",
    "num_duplicates = duplicated_df.shape[0]\n",
    "print(f\"complete dulpicate rows : {num_duplicates}\" )\n",
    "\n",
    "# check for duplicate record identification\n",
    "duplicate_values = df[\"record identification\"].duplicated()\n",
    "duplicated_rows = df[duplicate_values]\n",
    "num_duplicates = duplicated_rows.shape[0]\n",
    "print(f\"rows with duplicated record identification {num_duplicates}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc4c0c0",
   "metadata": {},
   "source": [
    "as we can see from the code above there are no duplicate rows or record identification\n",
    "TODO check if record identification means patiant number "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c865ecc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['WEST', 'STMW', 'SVHC', 'SVI', 'SVHD', 'other']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop \"record identification\" and \"referral source\" columns as they do not contain relvent data  \n",
    "df.drop(columns=[\"record identification\", \"referral source\"], inplace=True)\n",
    "col_info.pop(\"record identification\")\n",
    "col_info.pop(\"referral source\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "96a90eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# check all categorical data collumns have knwon categorical data \n",
    "# pattern checks integers or floats \n",
    "num_pattern = r\"\\d+(?:\\.\\d+)?\"\n",
    "\n",
    "for column, value_options in col_info.items():\n",
    "    # Only iterate over each categorical column\n",
    "    if value_options == continuous:\n",
    "        \n",
    "       # Check if each value in the column matches the integer or float pattern\n",
    "        non_numeric_values = df[column][(~df[column].isna()) & (~df[column].astype(str).str.match(num_pattern))]\n",
    "        # Convert non-numeric values to a list\n",
    "        non_numeric_values_list = non_numeric_values.tolist()\n",
    "        # Print the non-numeric values\n",
    "        if len(non_numeric_values_list) != 0:\n",
    "            print(f\"Non-numeric values in column '{column}':\")\n",
    "            print(non_numeric_values_list)\n",
    "    \n",
    "    else:\n",
    "\n",
    "        unique_values = df[column].unique()\n",
    "        # Check if all unique values are within known categories\n",
    "        unknown_values = [value for value in unique_values \n",
    "                          if (not pd.isna(value) ) and (value not in value_options)]\n",
    "        if len(unknown_values) != 0:    \n",
    "            print(f\"The following unknown categories are found in {column} column:\", unknown_values)\n",
    "    \n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01eda54c",
   "metadata": {},
   "source": [
    "as we can see from running the code above all values in the data base are known values \n",
    " there are no surprising values in any column \n",
    "TODO word this better \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d9160758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age info : max 65526 | min 1\n",
      "TSH info : max 99 | min 0.005\n",
      "T3 info : max 9.5 | min 0.05\n",
      "TT4 info : max 99 | min 10\n",
      "T4U info : max 2.33 | min 0.17\n",
      "FTI info : max 99 | min 1.4\n",
      "TBG info : max 96 | min 0.1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for col , values in col_info.items():\n",
    "    if values == continuous:    \n",
    "        print(f\"{col} info : max {df[col].dropna().max()} | min {df[col].dropna().min()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51558f1",
   "metadata": {},
   "source": [
    "a  max value 65526 for age is probubly an error this column should be inevstigated for further data problems \n",
    " \n",
    " \n",
    " TSH, T3, TT4, T4U, FTI  :  range of values seem plausible as they fall within the typical reference range.\n",
    "\n",
    "TBG (Thyroxine-Binding Globulin): The TBG values range from 0.1 to 96. While the maximum value seems high, it's not necessarily impossible. However, extremely high values should be reviewed for accuracy or potential outliers in the future.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1a3f53b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspecting age column for further data errors as explained above \n",
    "\n",
    "\n",
    "ages_gt_100 = df[df['age'] > 130]\n",
    "ages_gt_100.shape[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687e3a80",
   "metadata": {},
   "source": [
    "we assume that any age value larger then 130 is an error\n",
    "we can see that there is only a small number of rows with an age older then 130 \n",
    "we assume that removeing such a small number of rows from the dataset will no impact the prediction results greatly \n",
    "and so we will drop those rows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "57cdcf11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we assume that ages greater then 130 are probubly errors in the data and will be removed \n",
    "df = df.drop(df[df[\"age\"] > 130].index)\n",
    "# chceck to see max age again after changes \n",
    "df[\"age\"].max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1413396e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['normal', 'subnormal', 'hyperfunction'], dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace different diagnosis with a mapping of 3 bins \n",
    "\n",
    "normal = \"normal\"\n",
    "hyperfunction = \"hyperfunction\"\n",
    "subnormal = \"subnormal\"\n",
    "diagnosis_mapping = {\"A\":hyperfunction,\n",
    "            \"B\":hyperfunction,\n",
    "            \"C\":hyperfunction,\n",
    "            \"D\":hyperfunction,\n",
    "            \"O\":hyperfunction,\n",
    "            \"P\":hyperfunction,\n",
    "            \"Q\":hyperfunction,\n",
    "            \"T\":hyperfunction,\n",
    "            \"E\":subnormal,\n",
    "            \"F\":subnormal,\n",
    "            \"G\":subnormal,\n",
    "            \"H\":subnormal,\n",
    "            \"L\":subnormal,\n",
    "            \"M\":subnormal,\n",
    "            \"N\":subnormal,\n",
    "            \"K\":normal,\n",
    "            \"I\":normal,\n",
    "            \"J\":normal,\n",
    "            \"S\":normal,\n",
    "            \"-\":normal,\n",
    "            normal : normal,\n",
    "            hyperfunction : hyperfunction, \n",
    "            subnormal : subnormal\n",
    "          }\n",
    "\n",
    "def clearify_diagnosis(diagnosis):\n",
    "    \"\"\"\n",
    "    this function removes conflicting diagnosis and diagnosis which are not conclusive \n",
    "    \"\"\"\n",
    "    if diagnosis in diagnosis_mapping:\n",
    "        return diagnosis_mapping.get(diagnosis)\n",
    "    \n",
    "    curr_mapping = None\n",
    "    \n",
    "    for letter in diagnosis:\n",
    "        if letter == \"|\":\n",
    "            continue\n",
    "        \n",
    "        if letter not in diagnosis_mapping :\n",
    "            return pd.NA  # Drop the row if any letter is not in the mapping\n",
    "\n",
    "        curr_letter_mapping = diagnosis_mapping.get(letter) \n",
    "        if curr_mapping == None:\n",
    "            curr_mapping = curr_letter_mapping\n",
    "        elif curr_letter_mapping != curr_mapping:\n",
    "            return pd.NA # Drop row if conflicting diagnosis\n",
    "        \n",
    "    # if all possible diagnosis have the same mapping then return the mapping  \n",
    "    return curr_mapping\n",
    "\n",
    "df[\"diagnosis\"] = df[\"diagnosis\"].apply(clearify_diagnosis)\n",
    "df.dropna(subset=[\"diagnosis\"], inplace=True)\n",
    "\n",
    "df[\"diagnosis\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "59f90c92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 1])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# noww that we have finnished dealing with the data will encode all the categorical data to integeres \n",
    "# and the pd.NA to -999 \n",
    "encoding_map = {\n",
    "    \"F\":0,\n",
    "    \"M\":1,\n",
    "    \"f\":0,\n",
    "    \"t\":1,\n",
    "    pd.NA:-999,\n",
    "    normal : 0,\n",
    "    hyperfunction : 1, \n",
    "    subnormal : 2\n",
    "}\n",
    "\n",
    "def encode(value):\n",
    "    return encoding_map.get(value,value)\n",
    "\n",
    "df = df.applymap(encode)\n",
    "df[\"diagnosis\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b3ba712d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"pre_proc.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "81a5b436",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8377ac49",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X = df.drop(\"diagnosis\",axis=1)\n",
    "Y = df[\"diagnosis\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "log_regression = LogisticRegression(max_iter=10000, random_state=42)\n",
    "log_regression.fit(X_train, y_train)\n",
    "log_regression_y_pred = log_regression.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "259c0065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression \n",
      "Accuracy: 0.8866213151927438\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      1539\n",
      "           1       0.71      0.23      0.35        43\n",
      "           2       0.95      0.10      0.19       182\n",
      "\n",
      "    accuracy                           0.89      1764\n",
      "   macro avg       0.85      0.44      0.49      1764\n",
      "weighted avg       0.89      0.89      0.85      1764\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1535    3    1]\n",
      " [  33   10    0]\n",
      " [ 162    1   19]]\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, log_regression_y_pred)\n",
    "print (\"Logistic Regression \")\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, log_regression_y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, log_regression_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9d70496c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1764\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7b3dd376",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "random_forest = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "random_forest.fit(X_train, y_train)\n",
    "random_forest_y_pred = random_forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c5d75341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest \n",
      "Accuracy: 0.9863945578231292\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      1539\n",
      "           1       0.89      0.74      0.81        43\n",
      "           2       0.95      0.98      0.96       182\n",
      "\n",
      "    accuracy                           0.99      1764\n",
      "   macro avg       0.94      0.91      0.92      1764\n",
      "weighted avg       0.99      0.99      0.99      1764\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1529    3    7]\n",
      " [   8   32    3]\n",
      " [   2    1  179]]\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, random_forest_y_pred)\n",
    "print (\"Random Forest \")\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, random_forest_y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, random_forest_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a097a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d8814e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "65a055ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2344834862.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[39], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    normal = [ K, I, J, S, - ]\u001b[0m\n\u001b[0m                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# hyperfunction = [ A, B, C, D, O, P, Q, T ]\n",
    "# subnormal = [ E, F, G, H, L, M, N ]\n",
    "# normal = [ K, I, J, S, - ]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
